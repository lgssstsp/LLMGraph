{
    "Task Description": "Multi-task graph properties with GraphTheoryProp dataset. The GraphTheoryProp dataset is designed for multi-task benchmarking of 6 graph-theoretic properties: 3 at the node level (single source shortest paths (Dist.), node eccentricity (Ecc.), Laplacian features (Lap.)) and 3 at the graph level (graph connectivity (Conn.), diameter (Diam.), spectral radius (Rad.)). These tasks aim to assess the ability of a GNN to predict specific properties or the overall set of properties, which may involve shared subroutines such as graph traversal.",
    
    "Dataset Description": {
        "Source": "Synthetic dataset generated by Corso et al. (2020)",
        "Graph Types": "Undirected, unweighted graphs",
        "Node-Level Tasks": ["Distance (Dist.)", "Eccentricity (Ecc.)", "Laplacian features (Lap.)"],
        "Graph-Level Tasks": ["Graph Connectivity (Conn.)", "Diameter (Diam.)", "Spectral Radius (Rad.)"],
        "Graph Size Range": "15-24 nodes",
        "Node Features": "Random identifiers",
        "Data Size": "5,120 train, 640 validation, 1,280 test graphs"
    },

    "Splitting": "The dataset is divided into 5,120 training graphs, 640 validation graphs, and 1,280 test graphs, following the same splitting strategy as in Corso et al. (2020).",
    
    "Training": {
        "Learning Rate Strategy": {
            "Initial Learning Rate": "1 × 10^-3",
            "Reduce Factor": "0.5",
            "Patience Value": "15",
            "Stopping Learning Rate": "1 × 10^-6"
        },
        "Runs": "4 different seeds"
    },

    "Performance Measure": {
        "Metric": "Log10MSE (mean squared error on a logarithmic scale) between predicted and groundtruth values for each task",
        "Average Performance": "Combined average Log10MSE across all 6 tasks"
    },

    "Results": {
        "Model Performance": {
            "GIN": {
                "Layers": 8,
                "Average": "-3.19±0.11",
                "Dist.": "-2.81±0.11",
                "Ecc.": "-2.42±0.09",
                "Lap.": "-4.39±0.18",
                "Conn.": "-2.07±0.13",
                "Diam.": "-3.06±0.11",
                "Rad.": "-4.39±0.13"
            },
            "GIN-PE": {
                "Layers": 8,
                "Average": "-3.21±0.13",
                "Dist.": "-2.87±0.03",
                "Ecc.": "-2.83±0.07",
                "Lap.": "-3.99±0.04",
                "Conn.": "-2.00±0.15",
                "Diam.": "-3.27±0.07",
                "Rad.": "-4.31±0.15"
            },
            "GatedGCN": {
                "Layers": 8,
                "Average": "-3.22±0.13",
                "Dist.": "-2.76±0.17",
                "Ecc.": "-2.36±0.12",
                "Lap.": "-3.92±0.15",
                "Conn.": "-2.65±0.11",
                "Diam.": "-3.35±0.16",
                "Rad.": "-4.31±0.08"
            },
            "GatedGCN-PE": {
                "Layers": 8,
                "Average": "-3.51±0.11",
                "Dist.": "-3.23±0.08",
                "Ecc.": "-3.35±0.08",
                "Lap.": "-4.03±0.21",
                "Conn.": "-2.60±0.12",
                "Diam.": "-3.57±0.05",
                "Rad.": "-4.32±0.13"
            }
        }
    },

    "Summary": "The GraphTheoryProp dataset is used to evaluate the robustness of various GNN models to predict specific graph properties and to test the impact of using Graph Positional Encodings (PE). The GIN-PE model achieved superior performance in several tasks, while the GatedGCN-PE model showed competitive results across different properties, indicating the effectiveness of positional encodings in graph neural networks."
}



