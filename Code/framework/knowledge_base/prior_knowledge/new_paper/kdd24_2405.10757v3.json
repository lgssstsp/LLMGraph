{
    "meta_data": {
        "title": "Distribution Preserving Graph Backdoor Attack",
        "authors": [
            "Zhiwei Zhang",
            "Suhang Wang"
        ],
        "affiliations": [
            "Pennsylvania State University"
        ],
        "abstract": "Graph Neural Networks (GNNs) have greatly advanced the modeling of graph-structured data, making them integral in various tasks like node classification, link prediction, and graph classification. Despite their successes, GNNs are susceptible to backdoor attacks, typically designed to trigger or exploit specific conditions to manipulate model predictions. The challenge remains in generating unobtrusive and adaptive triggers that bypass existing outlier detection techniques while maintaining a high attack success rate. We propose DPGBA, a novel framework leveraging an OOD detector and adversarial learning for generating in-distribution triggers. Extensive experiments demonstrate DPGBAâ€™s capability to achieve high attack success rates across various GNN models without detection.",
        "keywords": [
            "Graph Neural Networks",
            "Backdoor Attacks",
            "Outlier Detection",
            "Adversarial Learning"
        ],
        "year": "2023",
        "venue": "arXiv",
        "doi link": null,
        "method name": "Distribution Preserving Graph Backdoor Attack (DPGBA)"
    },
    "relate work": {
        "related work category": [
            "Graph Neural Networks",
            "Backdoor Attacks",
            "Outlier Detection"
        ],
        "related papers": "[1] Zhang et al. (2021) conducted exploratory research within the field of graph backdoor attacks, advancing the concept of inserting predefined triggers within graph data. \n[2] Xi et al. (2021) explored the construction of adaptive triggers. \n[3] Dai et al. (2023) focused on defending against backdoor vulnerabilities.",
        "comparisons with related methods": "DPGBA differs from existing methods as it focuses on creating triggers that remain undetected by common outlier detection techniques while achieving high attack success rates."
    },
    "high_level_summary": {
        "summary of this paper": "This paper introduces DPGBA, a framework for executing backdoor attacks on Graph Neural Networks by creating distribution-preserving triggers that evade detection Yet link nodes to incorrect classifications.",
        "research purpose": "The goal is to generate in-distribution triggers for backdoor attacks on GNNs that can bypass common detection strategies while maintaining efficiency.",
        "research challenge": "Existing methods produce outlier triggers that are easily detectable, which undermines attack effectiveness.",
        "method summary": "DPGBA utilizes an OOD detector and adversarial learning to produce in-distribution triggers that deceive both natural classifiers and detector.",
        "conclusion": "Experiments indicate the utility of DPGBA across varying GNN architectures, demonstrating robustness against numerous detection methods."
    },
    "Method": {
        "description": "DPGBA leverages an OOD detector for training sub-network patterns as triggers, ensuring they are indistinguishable from clean data while achieving high attack success rates via adversarial learning.",
        "problem formultaion": "To ensure triggers are in-distribution, integrated with GNN classification, and evading detector recognition.",
        "feature processing": null,
        "model": "The model utilizes a multi-layer perceptron to synthesize node feature vectors and adjacency relations indicative of typical induced structures.",
        "tasks": [
            "Node Classification",
            "Link Prediction",
            "Graph Classification"
        ],
        "theoretical analysis": null,
        "complexity": "Time complexity remains linear with respect to node size within targeted graphs.",
        "algorithm step": "1. Define surrogate model 2. Apply bi-level optimization involving OOD detection and adversarial gaming for trigger generation 3. Evaluate trigger success rates."
    },
    "Experiments": {
        "datasets": [
            "Cora",
            "PubMed",
            "Flickr",
            "OGB-arxiv"
        ],
        "baselines": [
            "SBA-Samp",
            "SBA-Gen",
            "GTA",
            "UGBA"
        ],
        "evaluation metric": "Attack Success Rate, Clean Accuracy",
        "setup": "Conduct experiments on various datasets with test nodes excluded during trigger generator training.",
        "hyperparameters": "Tune parameters based on validation set performance.",
        "results": "DPGBA consistently surpasses baselines in attack success rate while maintaining clean accuracy due to its trigger strategies.",
        "performance": "DPGBA achieves over 90% attack success rate and effectively circumvents defenses.",
        "analysis": "Analysis highlights the matching of distribution characteristics of generated triggers with typical nodes.",
        "ablation study": "Ablations demonstrate criticality of in-distribution constraints and performance enhancement modules in achieving high attack success rates."
    },
    "conclusion": {
        "summary": "In summary, DPGBA effectively performs backdoor attacks on GNNs by generating imperceptible triggers impervious to outlier detection.",
        "future work": "Focus on refining trigger adaptability with minimal computational overhead and explore applications in dynamic network settings."
    }
}