{
    "Task Description": "Leaderboards for Node Property Prediction",
    "Dataset Name": "ogbn-products",
    "Dataset Link": "../nodeprop/#ogbn-products",
    "Rank": 11,
    "Method": "GIANT-XRT+SAGN+SLE (use raw text)",
    "External Data": "Yes",
    "Test Accuracy": "0.8622 ± 0.0022",
    "Validation Accuracy": "0.9363 ± 0.0005",
    "Contact": "mailto:ichien3@illinois.edu",
    "Paper Link": "https://arxiv.org/pdf/2111.00064.pdf",
    "Code Link": "https://github.com/elichienxD/SAGN_with_SLE",
    "Parameters": "1,548,382",
    "Hardware": "Tesla T4 (16GB GPU)",
    "Date": "Nov 8, 2021",
    "Local Paper PDF Path": "knowledge_base/Leaderboards_for_Node_Property_Prediction/ogbn-products/GIANT-XRT+SAGN+SLE_(use_raw_text).pdf",
    "Paper Summary": "The paper introduces a novel self-supervised learning framework called Graph Information Aided Node feature exTraction (GIANT) aimed at improving the extraction of numerical node features from raw data in graph neural network (GNN) pipelines. The central idea is to leverage the correlations between graph topology and node attributes through a self-supervised task termed neighborhood prediction, which is framed as an eXtreme Multi-label Classification (XMC) problem.\n\n### Key Design Aspects of the GIANT Framework:\n\n1. **Neighborhood Prediction Task:**\n   - GIANT introduces neighborhood prediction as a self-supervised learning task. The task aims to determine the neighborhood of each node based on its raw textual input. This representation serves as a multi-label output, which encodes whether one node is a neighbor of another.\n\n2. **Integration with Language Models:**\n   - The framework fine-tunes language models, such as BERT, using the neighborhood prediction task. The transformer model is treated as an encoder that maps raw text associated with each node to numerical features. By doing so, it effectively utilizes the structure of the graph while deriving features from unstructured data.\n\n3. **XMC Formalism:**\n   - The neighborhood prediction is related to XMC problems, enabling the use of advanced classification methods, particularly XR-Transformers, designed to handle large output spaces effectively. This integration allows for the exploration of complex relationships in graph structured data on a large scale.\n\n4. **PIFA Embedding:**\n   - The framework employs a technique called Positive Instance Feature Aggregation (PIFA) for generating embeddings from neighborhood information. It aggregates features from neighboring nodes, enhancing the representation of each node in the context of its local graph structure.\n\n5. **Hierarchical Label Clustering:**\n   - The method organizes the target labels (neighborhoods for nodes) hierarchically. A hierarchical clustering methodology is utilized to cluster labels effectively, which helps in solving the XMC problem in a multi-resolution manner, thereby improving the learning efficiency of the transformer model.\n\n6. **Utilization of XR-Transformers:**\n   - GIANT integrates XR-Transformers to solve the neighborhood prediction task. XR-Transformers leverage hierarchical label clustering and multi-resolution objectives for efficient training and representation learning, making them suitable for the large-scale nature of graph data.\n\n7. **Generalizability:**\n   - The proposed approach is designed to work with various types of input data formats, including raw text, image data, and potentially audio, demonstrating a versatile model design that adapts to different data modalities while maintaining the focus on self-supervised learning.\n\nOverall, the GIANT framework aims to overcome the limitations of traditional graph-agnostic feature extraction methods by explicitly incorporating graph structure into the feature extraction process. The innovative use of self-supervised neighborhood prediction underlines the importance of leveraging graph information to enhance node feature representation for improved graph neural network performance."
}