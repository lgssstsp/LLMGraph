{
    "Task Description": "Leaderboards for Link Property Prediction",
    "Dataset Name": "ogbl-wikikg2",
    "Dataset Link": "../linkprop/#ogbl-wikikg2",
    "Rank": 5,
    "Method": "InterHT+ (256dim)",
    "External Data": "No",
    "Test Accuracy": "0.7257 ± 0.0018",
    "Validation Accuracy": "0.7370 ± 0.0022",
    "Contact": "mailto:destin.bxwang@gmail.com",
    "Paper Link": "https://arxiv.org/abs/2202.04897v2",
    "Code Link": "https://github.com/destwang/InterHT",
    "Parameters": "148,000,738",
    "Hardware": "Tesla A100 (40GB)",
    "Date": "Dec 26, 2022",
    "Local Paper PDF Path": "knowledge_base/Leaderboards_for_Link_Property_Prediction/ogbl-wikikg2/InterHT+_(256dim).pdf",
    "Paper Summary": "The paper introduces two innovative distance-based methods for knowledge graph embeddings (KGE), named InterHT and InterHT+. These models aim to improve the interaction between head and tail entities in a knowledge graph, enhancing their representations for better performance in tasks like link prediction.\n\n### Model Design Aspects:\n\n1. **InterHT Method:**\n   - The core concept of InterHT is the interaction between the head (h) and tail (t) entities. While traditional KGE methods typically treat these entities separately, InterHT combines their information.\n   - The final head entity representation is generated by element-wise multiplying the original head entity representation with an auxiliary tail entity vector. Mathematically, this is expressed as:\n     \\[\n     ||h \\circ t - t \\circ h + r|| \n     \\]\n   - A similar approach is applied to derive the representation for the tail entity:\n     \\[\n     ||t \\circ (h + e) - h \\circ (t + e) + r||\n     \\]\n   - Here, \\( e \\) represents some additional embedding information to better integrate the entities' features.\n\n2. **InterHT+ Method:**\n   - Building on InterHT, the InterHT+ method integrates relation embeddings into the entity representations for improved performance.\n   - It modifies the head entity’s representation by further incorporating the relation embeddings. The equation for this extension is:\n     \\[\n     ||u \\cdot h \\circ t + h \\circ (u \\cdot r + e) - t \\circ (u \\cdot r + e) + r||\n     \\]\n   - In this equation, \\( u \\) is a constant scalar, integrating relation information into how head and tail entities define their interactions.\n\n3. **Entity Representation:**\n   - Both InterHT models employ a new method for entity representation referred to as \"DigPiece\" or \"Digraph Piece.\" This approach utilizes a subgraph to describe a target node, employing coarse-to-fine neighborhood information.\n   - The subgraph consists of various types of nodes, including anchors, in-direction neighbors, and out-direction neighbors. This fine-grained approach ensures that the representations encapsulate strong contextual features from the graph structure.\n\n4. **Loss Function:**\n   - The models utilize a self-adversarial negative sampling loss for training optimization, which includes penalties on distances between actual and predicted relationships, enhancing the embeddings' learning capacity.\n\nThese design considerations collectively focus on enriching the representations of entities by fostering interactions between them, thereby addressing limitations present in conventional KGE methods."
}