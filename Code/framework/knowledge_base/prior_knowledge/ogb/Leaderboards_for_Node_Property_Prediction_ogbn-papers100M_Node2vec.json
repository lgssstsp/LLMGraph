{
    "Task Description": "Leaderboards for Node Property Prediction",
    "Dataset Name": "ogbn-papers100M",
    "Dataset Link": "../nodeprop/#ogbn-papers100M",
    "Rank": 18,
    "Method": "Node2vec",
    "External Data": "No",
    "Test Accuracy": "0.5560 ± 0.0023",
    "Validation Accuracy": "0.5807 ± 0.0028",
    "Contact": "mailto:weihuahu@cs.stanford.edu",
    "Paper Link": "https://arxiv.org/abs/1607.00653",
    "Code Link": "https://github.com/snap-stanford/ogb/tree/master/examples/nodeproppred/papers100M",
    "Parameters": "14,215,818,412",
    "Hardware": "Xeon E7-8890x (1.5TB CPU)",
    "Date": "Jun 26, 2020",
    "Local Paper PDF Path": "knowledge_base/Leaderboards_for_Node_Property_Prediction/ogbn-papers100M/Node2vec.pdf",
    "Paper Summary": "The paper introduces **node2vec**, a framework designed for learning continuous feature representations of nodes in networks through a flexible random walk approach. This method aims to capture the complex relationships and connectivity patterns within networks in an efficient manner. Here are the key aspects of the model design discussed in the article:\n\n### 1. **Flexible Random Walks**\nNode2vec employs a **biased random walk** procedure to sample neighborhoods of nodes, which allows it to account for diverse connectivity patterns. The model incorporates parameters \\( p \\) and \\( q \\) to control the exploration behavior:\n- **Return parameter \\( p \\)**: This parameter governs the likelihood of revisiting a node during the random walk. A higher \\( p \\) favors local exploration, ensuring that the walk remains close to the starting node.\n- **In-out parameter \\( q \\)**: This parameter modulates the walk's directionality, enabling differentiation between inward and outward exploration. High \\( q \\) encourages exploration of nodes further away from the current node, which is effective for discovering broader community structures.\n\n### 2. **Objective Function**\nThe learning objective is to maximize the log-probability of observing a neighborhood of nodes \\( N^S(u) \\) given their feature representations. This is formalized as:\n\\[\n\\max \\log \\Pr(N^S(u)|f(u))\n\\]\nwhere \\( f \\) denotes the mapping of nodes to feature vectors.\n\n### 3. **Gradient-Based Optimization**\nNode2vec utilizes **stochastic gradient descent (SGD)** for optimizing the parameters of the node representations. The likelihood function leverages negative sampling, which simplifies computation during training by allowing the model to approximate the softmax function efficiently.\n\n### 4. **Embedding Generation**\nOnce the random walks are generated, they serve as input for the feature representation learning. The embeddings are designed to encode the neighborhood structure of nodes in a way that respects the underlying graph topology, thus producing richer node representations.\n\n### 5. **Generalization to Edge Representations**\nNode2vec can also derive feature representations for pairs of nodes (edges) by composing the learned features using specific binary operators (such as average, Hadamard, and others). This extension allows the model to be applicable for tasks such as link prediction.\n\n### 6. **Scalability and Efficiency**\nThe design of node2vec emphasizes computational efficiency and scalability, enabling it to handle networks with millions of nodes. The random walk strategy allows for the reuse of sampled nodes across different starting points, minimizing computational overhead.\n\n### 7. **User-Defined Parameters**\nThe framework provides flexibility by enabling users to tune parameters \\( p \\) and \\( q \\) according to specific network structures and prediction tasks without significantly increasing computational costs.\n\nIn summary, the **node2vec model** is built upon a flexible and efficient framework that allows for the capture of diverse network structures through innovative random walk strategies combined with a gradient-based learning approach."
}