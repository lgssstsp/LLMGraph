{
    "Task Description": "Leaderboards for Graph Property Prediction",
    "Dataset Name": "ogbg-molpcba",
    "Dataset Link": "../graphprop/#ogbg-mol",
    "Rank": 19,
    "Method": "GIN+virtual node",
    "External Data": "No",
    "Test Accuracy": "0.2703 ± 0.0023",
    "Validation Accuracy": "0.2798 ± 0.0025",
    "Contact": "mailto:weihuahu@cs.stanford.edu",
    "Paper Link": "https://arxiv.org/abs/1810.00826",
    "Code Link": "https://github.com/snap-stanford/ogb/tree/master/examples/graphproppred/mol",
    "Parameters": "3,374,533",
    "Hardware": "GeForce RTX 2080 (11GB GPU)",
    "Date": "Aug 11, 2020",
    "Local Paper PDF Path": "knowledge_base/Leaderboards_for_Graph_Property_Prediction/ogbg-molpcba/GIN+virtual_node.pdf",
    "Paper Summary": "The paper \"How Powerful Are Graph Neural Networks?\" introduces a theoretical framework to analyze the expressive power of Graph Neural Networks (GNNs) through a systematic examination of their design aspects, particularly focusing on their aggregation and combination methods.\n\n### Key Model Design Aspects\n\n1. **Neighborhood Aggregation**: \n   - GNNs utilize a neighborhood aggregation scheme, where the representation of a node is obtained by recursively aggregating representations from its neighboring nodes. This aggregation captures structural information within a k-hop neighborhood around each node.\n   - Different GNNs vary mainly in how they implement this aggregation process through various aggregation functions.\n\n2. **Design of Aggregation Functions**:\n   - The paper identifies that the choice of aggregation function significantly influences a GNN's expressiveness. For instance, functions can aggregate feature vectors either as sums, means, or other permutation-invariant functions.\n   - Specifically, the expressions for neighborhood aggregation and the subsequent node representations can be defined as:\n     \\[\n     a(k) = AGGREGATE(k) \\{ h(k-1)_u : u \\in N(v) \\}\n     \\]\n     \\[\n     h(k) = COMBINE(k)(h(k-1), a(k))\n     \\]\n   - The AGGREGATE function gathers features, while COMBINE involves combining the aggregated features with the node's previous representation.\n\n3. **Expressive Aggregation**:\n   - The authors show that for a GNN to have strong representational power, it must use expressive aggregation functions capable of distinguishing different multisets of features from neighboring nodes. This is connected to the idea of injective functions in aggregation.\n   - A key insight is that GNNs can match the expressive power of the Weisfeiler-Lehman (WL) test if they can model injective functions effectively.\n\n4. **Graph Isomorphism Networks (GIN)**:\n   - The authors develop a simple architecture called the Graph Isomorphism Network (GIN), which is designed to be maximally expressive. GIN follows:\n     \\[\n     h(k) = MLP(k) \\left( (1 + \\varepsilon(k)) \\cdot h(k-1) + \\sum_{u \\in N(v)} h(k-1)_u \\right)\n     \\]\n   - GIN utilizes a multi-layer perceptron (MLP) for combining the features and introduces a learnable parameter \\(\\varepsilon(k)\\) to control the aggregation process, thereby increasing its expressiveness.\n\n5. **Conditions for Maximally Powerful GNNs**:\n   - GNNs must satisfy specific conditions regarding neighborhood aggregation and graph-level readout functions to achieve maximum discrimination power equivalent to the WL test. These conditions include:\n     - The aggregation functions must be injective, ensuring different multisets yield different representations.\n     - The graph-level readout must also operate in a manner that preserves uniqueness in output representations based on input features.\n   \n6. **Theoretical Framework**:\n   - The paper establishes a theoretical framework to formalize these conditions, leading to a rigorous exploration of the representational capabilities of GNNs. This framework underscores that various existing GNN architectures inherently possess limitations due to their design choices and aggregation methods.\n\nIn summary, the paper emphasizes the importance of the aggregation design in GNNs and introduces the Graph Isomorphism Network as a method to achieve higher expressiveness by adhering to injective aggregation functions, thus broadening the theoretical understanding of GNN capabilities."
}