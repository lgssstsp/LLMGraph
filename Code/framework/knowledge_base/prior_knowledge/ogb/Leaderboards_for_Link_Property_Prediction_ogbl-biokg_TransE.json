{
    "Task Description": "Leaderboards for Link Property Prediction",
    "Dataset Name": "ogbl-biokg",
    "Dataset Link": "../linkprop/#ogbl-biokg",
    "Rank": 12,
    "Method": "TransE",
    "External Data": "No",
    "Test Accuracy": "0.7452 ± 0.0004",
    "Validation Accuracy": "0.7456 ± 0.0003",
    "Contact": "mailto:hyren@cs.stanford.edu",
    "Paper Link": "https://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf",
    "Code Link": "https://github.com/snap-stanford/ogb/tree/master/examples/linkproppred/biokg",
    "Parameters": "187,648,000",
    "Hardware": "GeForce RTX 2080 (11GB GPU)",
    "Date": "Jun 10, 2020",
    "Local Paper PDF Path": "knowledge_base/Leaderboards_for_Link_Property_Prediction/ogbl-biokg/TransE.pdf",
    "Paper Summary": "The paper introduces TransE, a novel approach for embedding entities and relationships in multi-relational data into low-dimensional vector spaces. The key design feature of TransE is its simplicity and efficiency, aiming to achieve effective performance with a reduced number of parameters, making it suitable for scaling to large datasets.\n\n### Model Overview\n- **Basic Concept**: TransE treats relationships as translations in the embedding space. For a triplet \\((h, \\ell, t)\\) (with \\(h\\) as the head entity, \\(t\\) as the tail entity, and \\(\\ell\\) as the relationship label), the model asserts that the embedding of the tail \\(t\\) should be close to the embedding of the head \\(h\\) plus a translation vector corresponding to the relationship \\(\\ell\\). This leads to the formulation \\(h + \\ell \\approx t\\).\n  \n- **Parameterization**: \n  - Each entity is assigned a single low-dimensional vector, and each relationship is represented as a single translation vector. This results in a low parameter count compared to more complex models that might utilize matrices for relationships, making it computationally efficient.\n  \n- **Hierarchical Representations**: The model is designed to effectively capture hierarchical relationships. The translation mechanism aligns well with inherent tree structures in knowledge bases (KBs), where sibling entities are close in the embedding space and parent-child relationships correspond to specific translations. \n\n### Learning Objective\n- **Energy-Based Framework**: The model formulates an energy-based criterion for learning the embeddings. It aims to minimize the distances (or energies) of valid triplets while maximizing those of corrupted triplets, which are generated by replacing either the head or tail of the triplet with random entities.\n  \n- **Loss Function**: The loss function is designed to reflect this objective, using a margin-based ranking criterion that encourages the model to assign lower energy to correct triplets than to corrupted ones. The approach relies on L1 or L2 norms to measure distances in the embedding space.\n\n### Gradient Optimization\n- **Stochastic Gradient Descent (SGD)**: The implementation employs stochastic gradient descent for optimization. During each iteration, entity embeddings are normalized, and small batches of triplets are sampled for updating embeddings based on the calculated gradients.\n\n### Main Innovations\n- **Translation as Relationship Representation**: By modeling relationships as simple translations, TransE effectively captures the essence of many relationships found in knowledge bases while maintaining computational efficiency through a minimal number of parameters.\n  \n- **Scalability and Efficiency**: The simplicity of the model allows it to be trained on large datasets with millions of entities and relationships, making it highly scalable.\n\nOverall, TransE distinguishes itself through its straightforward yet effective design, focusing on the core relationships in KBs and optimizing them efficiently without the complexity that often comes with more expressive models."
}