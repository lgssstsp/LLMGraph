{
    "Task Description": "Leaderboards for Link Property Prediction",
    "Dataset Name": "ogbl-ppa",
    "Dataset Link": "../linkprop/#ogbl-ppa",
    "Rank": 17,
    "Method": "DeepWalk",
    "External Data": "No",
    "Test Accuracy": "0.2888 Â± 0.0153",
    "Validation Accuracy": "Please tell us",
    "Contact": "mailto:taxuexh@sjtu.edu.cn",
    "Paper Link": "https://arxiv.org/pdf/1403.6652.pdf",
    "Code Link": "https://github.com/dmlc/dgl/tree/master/examples/pytorch/ogb/deepwalk",
    "Parameters": "150,138,741",
    "Hardware": "g4dn.2xlarge, T4 (15GB GPU)",
    "Date": "Jul 23, 2020",
    "Local Paper PDF Path": "knowledge_base/Leaderboards_for_Link_Property_Prediction/ogbl-ppa/DeepWalk.pdf",
    "Paper Summary": "The paper \"DeepWalk: Online Learning of Social Representations\" discusses a method for learning latent representations of vertices in a graph, particularly for social networks, utilizing concepts from deep learning and language modeling. Here's a summary focusing on the model design aspects:\n\n### Model Overview:\n\n1. **Input and Output:**\n   - The model takes a graph \\( G = (V, E) \\) as input, where \\( V \\) are the vertices (network members) and \\( E \\) are the edges (relationships). The output is a matrix of social representations \\( \\Phi \\) of dimension \\( |V| \\times d \\), where \\( d \\) is the number of latent dimensions.\n\n2. **Random Walks:**\n   - The core idea of DeepWalk is to utilize **truncated random walks** to generate local information from the graph. Each random walk is treated as a short sequence akin to a sentence in language modeling. The random walk process iteratively selects a vertex and samples from its neighbors until a predefined walk length is reached.\n\n3. **Representation Learning via Language Modeling:**\n   - DeepWalk generalizes the SkipGram model from natural language processing. Instead of predicting the next word in a sentence, it predicts the context (neighbor vertices in the random walk) of a given vertex. This is done by maximizing the likelihood of observing vertices in a specified context window.\n\n4. **Optimization Framework:**\n   - The method involves an optimization problem where the goal is to minimize the negative log-probability of observing neighbors given the central vertex in the context of the random walks. The optimization is performed using stochastic gradient descent (SGD), which updates the vertex representations based on the probability of neighboring vertices co-occurring.\n\n5. **Hierarchical Softmax:**\n   - To efficiently calculate the probabilities of neighboring vertices, DeepWalk employs a **Hierarchical Softmax** approach. Vertices are represented in a binary tree structure, where each leaf corresponds to a vertex. This allows for efficient distribution computation, reducing the complexity from \\( O(|V|) \\) to \\( O(\\log|V|) \\).\n\n6. **Parallelizability and Scalability:**\n   - DeepWalk is designed to be easily parallelizable, enabling multiple random walkers to explore different parts of the graph simultaneously. This is particularly beneficial for handling large-scale graphs. An asynchronous version of SGD is also utilized, allowing updates from multiple workers without the need for locking shared parameters.\n\n7. **Adaptability and Community Awareness:**\n   - The method is adaptable to changing network dynamics, encouraging continuous learning as new relations occur without requiring complete re-training. The representation learned captures community membership information, allowing for smooth decision boundaries in classification tasks.\n\n8. **Implementation Variants:**\n   - Variants of DeepWalk include a streaming approach where small walks are passed to the representation learning process directly (useful for dynamic graphs) and models utilizing non-random walks, allowing the transformation of user navigation into features for representation learning.\n\nThe design of DeepWalk revolves around combining random walks with language modeling techniques to encode social structures effectively, making it a versatile model for network representation learning."
}