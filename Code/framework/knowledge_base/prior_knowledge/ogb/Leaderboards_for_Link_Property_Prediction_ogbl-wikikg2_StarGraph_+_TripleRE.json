{
    "Task Description": "Leaderboards for Link Property Prediction",
    "Dataset Name": "ogbl-wikikg2",
    "Dataset Link": "../linkprop/#ogbl-wikikg2",
    "Rank": 4,
    "Method": "StarGraph + TripleRE",
    "External Data": "No",
    "Test Accuracy": "0.7286 ± 0.0009",
    "Validation Accuracy": "0.7335 ± 0.0011",
    "Contact": "mailto:fenglinghui@360.cn",
    "Paper Link": "https://arxiv.org/abs/2205.14209",
    "Code Link": "https://github.com/hzli-ucas/StarGraph",
    "Parameters": "93,039,522",
    "Hardware": "Tesla A100 (40GB)",
    "Date": "Jan 3, 2023",
    "Local Paper PDF Path": "knowledge_base/Leaderboards_for_Link_Property_Prediction/ogbl-wikikg2/StarGraph_+_TripleRE.pdf",
    "Paper Summary": "The paper presents a novel method called **StarGraph** aimed at enhancing knowledge representation learning using incomplete two-hop subgraphs. The approach is designed to address the limitations of traditional embedding methods that primarily rely on a single embedding vector for each entity, thereby neglecting the rich contextual information of neighboring entities in knowledge graphs.\n\n### Methodology Overview\n\n1. **Subgraph Generation**:\n   - **Anchor Selection**: A small fraction of nodes is chosen as anchors based on their degree of centrality, utilizing a deterministic selection strategy. The generation of the anchor set includes a hyper-parameter called **skip-threshold**, which avoids densely surrounding nodes with too many anchors, ensuring a more balanced anchor distribution.\n   - **Subgraph Creation**: For each target node, a proper incomplete two-hop subgraph is constructed by sampling a fixed number of anchors and additional nodes within its two-hop neighborhood. This aims to ensure sufficient representation while minimizing redundancy.\n\n2. **Subgraph Encoding**:\n   - A **self-attention network** is employed to encode the generated subgraph. The self-attention mechanism is modified to enhance efficiency and reduce computational burden, allowing for efficient integration of information from all nodes within the subgraph.\n   - **Reduced Attention Module**: This module has been designed to lower computational complexity by modifying the dimensions of the transformation matrices within the attention mechanism, allowing for the processing of the graph without wasting significant resources on calculations that do not contribute meaningfully to performance.\n   - **Path Information Fusion**: The model incorporates path information as part of the node embeddings to better represent the relationships between nodes, adapting concepts from the knowledge graph embedding literature to inform how theoretical constructs (like anchors, paths, and tokens) merge in representation learning.\n   - **Supplementary Nodes**: Along with anchors, the subgraph may also include sampled nodes from the graph to enrich the information available for learning representations, ensuring that unique information from various nodes is considered in the representation of relationships.\n\n3. **Score Function**:\n   - StarGraph adopts a modified distance-based score function inspired by existing models, designed to compute the plausibility of triples. The scoring incorporates embeddings of entities and relations while allowing for effective training through a self-adversarial negative sampling loss, optimizing the computed scores for improved performance.\n\n### Conclusion\n\nStarGraph innovatively combines neighborhood information through its targeted approach of incomplete subgraphs and enhanced self-attention encoding, aiming to leverage the structural characteristics of knowledge graphs effectively. The methodological adjustments, particularly around the reduced attention mechanism and the way path information is fused, signify key contributions to the efficiency and effectiveness of knowledge representation learning."
}