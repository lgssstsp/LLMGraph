{
    "Task Description": "Leaderboards for Graph Property Prediction",
    "Dataset Name": "ogbg-molhiv",
    "Dataset Link": "../graphprop/#ogbg-mol",
    "Rank": 12,
    "Method": "CIN-small",
    "External Data": "No",
    "Test Accuracy": "0.8055 ± 0.0104",
    "Validation Accuracy": "0.8310 ± 0.0102",
    "Contact": "mailto:ffrasca@twitter.com",
    "Paper Link": "https://arxiv.org/abs/2106.12575",
    "Code Link": "https://github.com/twitter-research/cwn",
    "Parameters": "138,337",
    "Hardware": "Tesla V100 (16GB)",
    "Date": "Aug 31, 2021",
    "Local Paper PDF Path": "knowledge_base/Leaderboards_for_Graph_Property_Prediction/ogbg-molhiv/CIN-small.pdf",
    "Paper Summary": "The paper introduces **Cellular Weisfeiler Lehman Networks (CWNs)** as a novel message-passing architecture based on **regular cell complexes**. Here are the key model design aspects discussed in the article:\n\n### Overview of CWNs\n1. **Decoupling Input and Computational Structure**: CWNs aim to overcome limitations faced by Graph Neural Networks (GNNs) by utilizing a message-passing framework on cell complexes, separating the input graph structure from the computational graph structure.\n\n2. **Message-Passing Mechanism**:\n   - **Higher-Dimensional Constructs**: Each node (0-cells) and edge (1-cells) in the input graph can be associated with higher-dimensional constructs (2-cells and beyond), allowing for richer interactions.\n   - **Aggregation Functions**: Two types of messages are defined:\n     - Messages passed from lower-dimensional cells (e.g., atoms) to higher-dimensional cells (e.g., bonds and rings).\n     - Messages between adjacent higher-dimensional cells (e.g., bonds that are part of the same ring).\n   - The update operation takes incoming messages into account, updating the features of the cells accordingly.\n\n3. **Hierarchical Message Passing**: CWNs provide a multi-dimensional and hierarchical message-passing process that iterates through L layers. Each layer aggregates information from related cells, reducing the required number of layers for capturing long-range dependencies.\n\n### Architectural Features\n1. **Cell Features**: \n   - **0-cells (Vertices)**: Initialized with original node features or learned embeddings.\n   - **1-cells (Edges)**: Assigned feature values based on edges, either as learned embeddings or sums of adjacent node features.\n   - **2-cells (Cycles/Rings)**: Induced from cycles in the graph, with feature assignments based on the contained 0-cells.\n\n2. **Coloring Mechanism**:\n   - CWLs (Cellular Weisfeiler Lehman) is a color refinement method adapted for regular cell complexes. All cells are initialized with the same color, and subsequent iterations refine this coloring based on adjacent relationships and complexity (e.g., boundary and co-boundary relationships).\n\n3. **Hierarchy in Features and Layer Structure**: \n   - CWNs are structured to reflect the hierarchy in molecular structures, enabling the model to capture complex relationships like those found in chemical compounds. The convolutional-like operations allow for a strong representation of the topological features of molecules.\n\n4. **Equivariance Properties**: \n   - CWNs maintain a form of permutation equivariance such that the output remains consistent under permutations of cell indexing, allowing the model to generalize over different graph configurations.\n\n### Update Function\n- The core update mechanism integrates messages from neighboring cells through learnable parameters and potentially non-linear transformations. The form of this update follows:\n   \\[\n   h^{t+1} = U(h^t, m_t(\\sigma), m_t(\\sigma))\n   \\]\n   where \\(U\\) represents the update function and \\(m_t\\) are the messages from the upper and boundary adjacent cells.\n\n### Conclusion\nCWNs present a structurally innovative approach by using regular cell complexes to enhance the expressive power of GNNs while maintaining flexibility in structure and dimensionality. They introduce a more robust way to encode and process interactions within graphs, particularly advantageous in applications like molecular graph prediction."
}